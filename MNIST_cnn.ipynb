{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YZxdEpCSnu3",
        "colab_type": "text"
      },
      "source": [
        "# Simple CNN for Image Classification\n",
        "-  dataset: MNIST\n",
        "- TensorFlow: tf.layers, tf.Estimator\n",
        "- Colab TensorBoard monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMPDCj8hwqUx",
        "colab_type": "text"
      },
      "source": [
        "##[optional] Get ngrock and run it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGTpxe56vbNh",
        "colab_type": "code",
        "outputId": "f52b6e05-b527-4cc7-ff24-1da878c092e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "![[ -d \"ngrook\" ]] \\\n",
        "  && wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip \\\n",
        "  && unzip ngrok-stable-linux-amd64.zip\n",
        "  \n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://90460a22.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6GX9nHfwxLT",
        "colab_type": "text"
      },
      "source": [
        "## Start TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ftxvdNf7zPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR=\"/tmp/mnist_convnet_model\"\n",
        "! rm -rf $MODEL_DIR\n",
        "! mkdir $MODEL_DIR\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(MODEL_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itw9uDc8tX2S",
        "colab_type": "text"
      },
      "source": [
        "# Define Estimator functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BLHeKUFlV79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0gwXbh4lmHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model_fn(optimizer, cnn_config):\n",
        "  \n",
        "  def _cnn(input_layer, config):\n",
        "    net = []\n",
        "    last_layer=input_layer\n",
        "    for idx, (k, s, f) in enumerate(config):\n",
        "      with tf.name_scope('conv'+str(idx)) as scope:\n",
        "        conv = tf.layers.conv2d(inputs=last_layer, filters=f,\n",
        "                                kernel_size=k, padding=\"same\",\n",
        "                                activation=tf.nn.relu)\n",
        "        net.append(conv)\n",
        "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=s,\n",
        "                                       strides=s)\n",
        "        net.append(pool)\n",
        "        last_layer = net[-1]\n",
        "    \n",
        "    return net, last_layer\n",
        "    \n",
        "  \n",
        "  def _model_fn(features, labels, mode, params=None):\n",
        "    \"\"\"Model function for CNN.\"\"\"\n",
        "    \n",
        "    # Input Layer\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "\n",
        "    # Convolutional Layers\n",
        "    _, last_layer = _cnn(input_layer, cnn_config)\n",
        "    \"\"\"\n",
        "    last_layer = input_layer\n",
        "    net = []\n",
        "    for idx, (k, s, f) in enumerate(cnn_config):\n",
        "      with tf.name_scope('conv'+str(idx)) as scope:\n",
        "        conv = tf.layers.conv2d(inputs=last_layer, filters=f,\n",
        "                                kernel_size=k, padding=\"same\",\n",
        "                                activation=tf.nn.relu)\n",
        "        net.append(conv)\n",
        "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=s,\n",
        "                                       strides=s)\n",
        "        net.append(pool)\n",
        "        last_layer = net[-1]\n",
        "    \"\"\"\n",
        "    # Reshape\n",
        "    embedding = tf.reshape(last_layer,\n",
        "                            [-1, 7 * 7 * 64])\n",
        "    \n",
        "    # Dense Layer\n",
        "    dense = tf.layers.dense(inputs=embedding,\n",
        "                            units=1024,\n",
        "                            activation=tf.nn.relu)\n",
        "    \n",
        "    dropout = tf.layers.dropout(inputs=dense,\n",
        "                                rate=0.4,\n",
        "                                training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    # Logits Layer\n",
        "    logits = tf.layers.dense(inputs=dropout,\n",
        "                             units=10)\n",
        "\n",
        "    # Compute predictions\n",
        "    predicted_classes = tf.argmax(input=logits, axis=1)\n",
        "    \n",
        "    \n",
        "    predictions = {\n",
        "        'classes': predicted_classes[:, tf.newaxis],\n",
        "        'probabilities': tf.nn.softmax(logits, name=\"softmax_tensor\"),\n",
        "        'logits': logits,\n",
        "    }\n",
        "    \n",
        "    # PREDICT\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                        predictions=predictions)\n",
        "\n",
        "    # Calculate Loss\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,\n",
        "                                                  logits=logits)\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = tf.metrics.accuracy(labels=labels,\n",
        "                                   predictions=predicted_classes,\n",
        "                                   name='acc_op')\n",
        "    \n",
        "    metrics = {'accuracy': accuracy}\n",
        "    tf.summary.scalar('accuracy', accuracy[1])\n",
        "    \n",
        "    # EVAL\n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "      return tf.estimator.EstimatorSpec(mode,\n",
        "                                        loss=loss, \n",
        "                                        eval_metric_ops=metrics)\n",
        "    \n",
        "    # TRAIN\n",
        "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
        "    \n",
        "    train_op = optimizer.minimize(loss, \n",
        "                                  global_step=tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "  \n",
        "  return _model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSU9zgB6nxzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_input_fn(features,\n",
        "                        labels,\n",
        "                        batch_size=100,\n",
        "                        num_epochs=None,\n",
        "                        shuffle=True):\n",
        "\n",
        "  train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": features},\n",
        "                                                      y=labels,\n",
        "                                                      batch_size=batch_size,\n",
        "                                                      num_epochs=num_epochs,\n",
        "                                                      shuffle=shuffle)\n",
        "  return train_input_fn\n",
        "\n",
        "def make_eval_input_fn(features,\n",
        "                       labels):\n",
        "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": features},\n",
        "                                                     y=labels,\n",
        "                                                     num_epochs=1,\n",
        "                                                     shuffle=False)\n",
        "  \n",
        "  return eval_input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEPGaPm0tiIO",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9rswkoVnW5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load training and eval data\n",
        "((train_data, train_labels),\n",
        " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_data = train_data/np.float32(255)\n",
        "train_labels = train_labels.astype(np.int32)  # not required\n",
        "\n",
        "eval_data = eval_data/np.float32(255)\n",
        "eval_labels = eval_labels.astype(np.int32)  # not required"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z67gPXnvtpHR",
        "colab_type": "text"
      },
      "source": [
        "# Create the Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvpal_2nqV3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate=0.1\n",
        "batch_size=100\n",
        "max_steps=20000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OvbvjihxE_F",
        "colab_type": "code",
        "outputId": "030fedbf-c225-475a-a24a-0fab21d4fe9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Create the Estimator\n",
        "my_checkpointing_config = tf.estimator.RunConfig(\n",
        "    save_checkpoints_steps = 2000,\n",
        "    #keep_checkpoint_max = 10,\n",
        "    log_step_count_steps = 500,\n",
        "    tf_random_seed=2020         # for reproducibility\n",
        ")\n",
        "\n",
        "train_spec = tf.estimator.TrainSpec(\n",
        "    input_fn=make_train_input_fn(train_data,\n",
        "                                 train_labels,\n",
        "                                 batch_size=batch_size),\n",
        "    max_steps=max_steps)\n",
        "\n",
        "eval_spec = tf.estimator.EvalSpec(\n",
        "    input_fn=make_eval_input_fn(eval_data,\n",
        "                                eval_labels),\n",
        "    steps=None,          # use complete eval set\n",
        "    start_delay_secs=0,  # start immediately\n",
        "    throttle_secs=10)    # minimum delay between evaluations\n",
        "\n",
        "cnn_config = [ [5, 2, 32], [5, 2, 64] ]\n",
        "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "classifier = tf.estimator.Estimator(\n",
        "  model_fn=make_model_fn(optimizer, cnn_config),\n",
        "  model_dir=MODEL_DIR,\n",
        "  config=my_checkpointing_config\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': 2020, '_save_summary_steps': 100, '_save_checkpoints_steps': 2000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6f3ad10278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_model_fn.<locals>._model_fn at 0x7f6f3acfb1e0>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cQXA_4Pt4uQ",
        "colab_type": "text"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udsKrv2Kt0nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3706
        },
        "outputId": "ce541696-dec7-4b44-d953-f3175e62339c"
      },
      "source": [
        "tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 2000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-4-a5b5e39cb7f7>:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-a5b5e39cb7f7>:13: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-a5b5e39cb7f7>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-a5b5e39cb7f7>:53: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3330808, step = 0\n",
            "INFO:tensorflow:global_step/sec: 187.618\n",
            "INFO:tensorflow:loss = 0.059926547, step = 500 (2.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 199.711\n",
            "INFO:tensorflow:loss = 0.04038762, step = 1000 (2.504 sec)\n",
            "INFO:tensorflow:global_step/sec: 192.349\n",
            "INFO:tensorflow:loss = 0.011947789, step = 1500 (2.603 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:04:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:04:52\n",
            "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9881, global_step = 2000, loss = 0.03265\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/mnist_convnet_model/model.ckpt-2000\n",
            "INFO:tensorflow:global_step/sec: 145.803\n",
            "INFO:tensorflow:loss = 0.11477423, step = 2000 (3.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.292\n",
            "INFO:tensorflow:loss = 0.017336939, step = 2500 (2.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 185.69\n",
            "INFO:tensorflow:loss = 0.031510018, step = 3000 (2.692 sec)\n",
            "INFO:tensorflow:global_step/sec: 194.985\n",
            "INFO:tensorflow:loss = 0.016891219, step = 3500 (2.565 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:05:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:05:03\n",
            "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.9925, global_step = 4000, loss = 0.02439416\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/mnist_convnet_model/model.ckpt-4000\n",
            "INFO:tensorflow:global_step/sec: 156.802\n",
            "INFO:tensorflow:loss = 0.015847273, step = 4000 (3.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 197.405\n",
            "INFO:tensorflow:loss = 0.0032702447, step = 4500 (2.537 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.804\n",
            "INFO:tensorflow:loss = 0.009170505, step = 5000 (2.550 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.206\n",
            "INFO:tensorflow:loss = 0.0039080177, step = 5500 (2.547 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:05:14Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-6000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:05:14\n",
            "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.9934, global_step = 6000, loss = 0.019465132\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: /tmp/mnist_convnet_model/model.ckpt-6000\n",
            "INFO:tensorflow:global_step/sec: 148.847\n",
            "INFO:tensorflow:loss = 0.0019652643, step = 6000 (3.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.776\n",
            "INFO:tensorflow:loss = 0.010729309, step = 6500 (2.542 sec)\n",
            "INFO:tensorflow:global_step/sec: 193.712\n",
            "INFO:tensorflow:loss = 0.036434382, step = 7000 (2.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.77\n",
            "INFO:tensorflow:loss = 0.041259117, step = 7500 (2.554 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:05:25Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-8000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:05:25\n",
            "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.9931, global_step = 8000, loss = 0.024966273\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: /tmp/mnist_convnet_model/model.ckpt-8000\n",
            "INFO:tensorflow:global_step/sec: 156.354\n",
            "INFO:tensorflow:loss = 0.005041751, step = 8000 (3.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.394\n",
            "INFO:tensorflow:loss = 0.044620737, step = 8500 (2.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 193.712\n",
            "INFO:tensorflow:loss = 0.003555102, step = 9000 (2.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 194.721\n",
            "INFO:tensorflow:loss = 0.001645472, step = 9500 (2.561 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:05:36Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:05:36\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9931, global_step = 10000, loss = 0.025474949\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/mnist_convnet_model/model.ckpt-10000\n",
            "INFO:tensorflow:global_step/sec: 151.689\n",
            "INFO:tensorflow:loss = 0.0005418965, step = 10000 (3.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 189.515\n",
            "INFO:tensorflow:loss = 0.0015000765, step = 10500 (2.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 189.391\n",
            "INFO:tensorflow:loss = 0.0008770332, step = 11000 (2.639 sec)\n",
            "INFO:tensorflow:global_step/sec: 188.732\n",
            "INFO:tensorflow:loss = 0.0020899882, step = 11500 (2.650 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:05:47Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-12000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:05:47\n",
            "INFO:tensorflow:Saving dict for global step 12000: accuracy = 0.9941, global_step = 12000, loss = 0.024967555\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: /tmp/mnist_convnet_model/model.ckpt-12000\n",
            "INFO:tensorflow:global_step/sec: 154.309\n",
            "INFO:tensorflow:loss = 0.00057428813, step = 12000 (3.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.073\n",
            "INFO:tensorflow:loss = 0.0006599907, step = 12500 (2.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 197.039\n",
            "INFO:tensorflow:loss = 0.0007609691, step = 13000 (2.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.187\n",
            "INFO:tensorflow:loss = 8.571418e-05, step = 13500 (2.550 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:05:58Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-14000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:05:58\n",
            "INFO:tensorflow:Saving dict for global step 14000: accuracy = 0.9934, global_step = 14000, loss = 0.023863802\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: /tmp/mnist_convnet_model/model.ckpt-14000\n",
            "INFO:tensorflow:global_step/sec: 148.988\n",
            "INFO:tensorflow:loss = 0.00031219277, step = 14000 (3.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.837\n",
            "INFO:tensorflow:loss = 0.0060351444, step = 14500 (2.541 sec)\n",
            "INFO:tensorflow:global_step/sec: 194.923\n",
            "INFO:tensorflow:loss = 0.0011946674, step = 15000 (2.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.892\n",
            "INFO:tensorflow:loss = 1.259881e-05, step = 15500 (2.543 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 16000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:06:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-16000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:06:09\n",
            "INFO:tensorflow:Saving dict for global step 16000: accuracy = 0.993, global_step = 16000, loss = 0.029575499\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16000: /tmp/mnist_convnet_model/model.ckpt-16000\n",
            "INFO:tensorflow:global_step/sec: 155.87\n",
            "INFO:tensorflow:loss = 0.001514205, step = 16000 (3.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.563\n",
            "INFO:tensorflow:loss = 2.3140097e-05, step = 16500 (2.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.86\n",
            "INFO:tensorflow:loss = 0.00017974025, step = 17000 (2.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.024\n",
            "INFO:tensorflow:loss = 3.9729152e-06, step = 17500 (2.547 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18000 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-02T18:06:19Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-18000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-02-18:06:20\n",
            "INFO:tensorflow:Saving dict for global step 18000: accuracy = 0.9936, global_step = 18000, loss = 0.026924493\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18000: /tmp/mnist_convnet_model/model.ckpt-18000\n",
            "INFO:tensorflow:global_step/sec: 156.23\n",
            "INFO:tensorflow:loss = 8.497239e-06, step = 18000 (3.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.953\n",
            "INFO:tensorflow:loss = 0.00019246626, step = 18500 (2.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.168\n",
            "INFO:tensorflow:loss = 1.7161929e-05, step = 19000 (2.562 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9ckpVCFwe1n",
        "colab_type": "text"
      },
      "source": [
        "# Stop Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfnpAQa6vhqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get_ipython().system_raw('pkill tensorboard')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}